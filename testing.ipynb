{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from kerax.layers import Conv2D, Dense, Flatten, Input, BatchNormalization, Activation, Add\n",
    "from kerax.models import Model, Sequential\n",
    "from kerax.losses import CategoricalCrossEntropy\n",
    "import numpy as np\n",
    "from kerax import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.random.random((128,28,28,1))\n",
    "train_y = np.random.random((128, 10))\n",
    "\n",
    "val_x = np.random.random((128, 28,28,1))\n",
    "val_y = np.random.random((128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((28, 28, 1))\n",
    "conv1 = Conv2D(64, 3, activation=activations.ReLU)(inputs)\n",
    "conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv1)\n",
    "act1 = Activation('relu')(conv1)\n",
    "conv3 = Conv2D(128, 3, padding='same')(act1)\n",
    "act2 = Activation('relu')(conv3)\n",
    "conv4 = Conv2D(128, 3, padding='same')(act2)\n",
    "add = Add()([conv2, conv4])\n",
    "flatten = Flatten()(add)\n",
    "dense1 = Dense(512, activation='relu')(flatten)\n",
    "dense2 = Dense(10, activation='softmax')(dense1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=inputs, output=dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(CategoricalCrossEntropy, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 4/4 [00:02<00:00,  1.36it/s, loss=101.44027, remaining_epochs=9]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.62it/s, loss=53.072952, remaining_epochs=8]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.33it/s, loss=31.527235, remaining_epochs=7]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.32it/s, loss=26.267319, remaining_epochs=6]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.56it/s, loss=18.535124, remaining_epochs=5]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.48it/s, loss=17.189745, remaining_epochs=4]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.55it/s, loss=11.5807905, remaining_epochs=3]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.48it/s, loss=10.242433, remaining_epochs=2]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.51it/s, loss=11.821889, remaining_epochs=1]\n",
      "100%|████████████████████████████████████████| 4/4 [00:01<00:00,  3.51it/s, loss=10.098997, remaining_epochs=0]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"hazem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, 3, input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Convolutional Layer with input shape (None, 28, 28, 1) and output shape (None, 26, 26, 32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Conv2D(32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6721b10ec9b0eeb463be84ab6ef1ed3e9e9b165baec57fa1847c389edb595caf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('jax': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
