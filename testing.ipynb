{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 05:30:07.413000: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from kerax.layers import Conv2D, Dense, Flatten, Input, Activation, Add, Concatenate\n",
    "from kerax.models import Model\n",
    "from jax.random import PRNGKey\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = random.normal(key=PRNGKey(3), shape=(2, 28, 28, 1))\n",
    "\n",
    "# train_x = random.normal(key=PRNGKey(3), shape=(128, 28, 28, 1))\n",
    "# train_y = random.randint(key=PRNGKey(34), shape=(128, 1), minval=0, maxval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "conv1 = Conv2D(64, 3, key=PRNGKey(100), padding='same')(inputs)\n",
    "act1 = Activation('leaky_relu')(conv1)\n",
    "conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(act1)\n",
    "act2 = Activation('leaky_relu')(conv3)\n",
    "conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(act2)\n",
    "# add1 = Add()([conv4, act2])\n",
    "\n",
    "# inputs2 = Input(shape=(28, 28, 1))\n",
    "# inputs2_conv1 = Conv2D(32, 3, key=PRNGKey(100), padding='same')(inputs2)\n",
    "# inputs2_act1 = Activation('relu')(inputs2_conv1)\n",
    "# inputs2_conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs2_act1)\n",
    "# inputs2_act2 = Activation('gelu')(inputs2_conv3)\n",
    "# inputs2_conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(inputs2_act2)\n",
    "# add2 = Add()([inputs2_conv4, inputs2_act2])\n",
    "\n",
    "\n",
    "# inputs3 = Input(shape=(28, 28, 1))\n",
    "# inputs3_conv1 = Conv2D(32, 3, key=PRNGKey(100), padding='same')(inputs3)\n",
    "# inputs3_act1 = Activation('relu')(inputs3_conv1)\n",
    "# inputs3_conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs3_act1)\n",
    "# inputs3_act2 = Activation('gelu')(inputs3_conv3)\n",
    "# inputs3_conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs3_act2)\n",
    "# inputs3_conv5 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(inputs3_conv4)\n",
    "# add3 = Add()([inputs3_conv5, inputs3_act2])\n",
    "\n",
    "# cat = Concatenate()([add1, add2, add3])\n",
    "\n",
    "flatten1 = Flatten()(conv4)\n",
    "flatten2 = Flatten()(act2)\n",
    "dense1 = Dense(512, activation='leaky_relu')(flatten1)\n",
    "dense2 = Dense(512)(flatten2)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "output2 = Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(inputs):\n",
    "    branches = [OrderedDict([(_input.name, _input)]) for _input in inputs]\n",
    "    main_layers = OrderedDict()\n",
    "    def _traverse(root, branch_index, visited):\n",
    "        nonlocal branches\n",
    "        for r in root._node_container.outbound_nodes:\n",
    "            if r.name not in visited:\n",
    "                visited.add(r.name)\n",
    "                if branch_index > 0 and r.name in branches[branch_index-1] and r.name not in main_layers:\n",
    "                    del(branches[branch_index-1][r.name])\n",
    "                    main_layers[r.name] = r\n",
    "                elif r.name in main_layers:\n",
    "                    continue\n",
    "                else:\n",
    "                    branches[branch_index][r.name] = r\n",
    "                _traverse(r, branch_index, visited)\n",
    "\n",
    "    for branch_index, _input in enumerate(inputs, start=0):\n",
    "        _traverse(root=_input, branch_index=branch_index, visited=set())\n",
    "\n",
    "    def create_graph():\n",
    "        nonlocal branches\n",
    "        requires_output_from = OrderedDict()\n",
    "        requires_output_to = OrderedDict()\n",
    "        layers = OrderedDict([(layer_name, layer) for branch in branches for layer_name, layer in branch.items()])\n",
    "\n",
    "        layers.update(main_layers)\n",
    "        for layer_name, layer in layers.items():\n",
    "            required_outputs_from = [node.name for node in layer._node_container.inbound_nodes]\n",
    "            required_outputs_to = [node.name for node in layer._node_container.outbound_nodes]\n",
    "            requires_output_from[layer_name] = required_outputs_from\n",
    "            requires_output_to[layer_name] = required_outputs_to\n",
    "\n",
    "\n",
    "        return layers, requires_output_from, requires_output_to\n",
    "\n",
    "    layers, requires_output_from, requires_output_to = create_graph()\n",
    "\n",
    "    params = []\n",
    "    for l_name, l_param in requires_output_from.items():\n",
    "        params.append(layers[l_name].params)\n",
    "\n",
    "    params = tuple(params)\n",
    "\n",
    "    def flow_input(params, tensors):\n",
    "        saved_outputs = OrderedDict()\n",
    "        nonlocal layers, requires_output_from, requires_output_to\n",
    "        consumed_indices = 0\n",
    "        for param, (key, val) in zip(params, requires_output_from.items()):\n",
    "            if len(val) == 0:\n",
    "                saved_outputs[key] = layers[key].call_with_external_weights(param, tensors[consumed_indices])\n",
    "                consumed_indices += 1\n",
    "            else:\n",
    "                if len(val) == 1:\n",
    "                    saved_outputs[key] = layers[key].call_with_external_weights(param, saved_outputs[val[0]])\n",
    "                else:\n",
    "                    saved_outputs[key] = layers[key].call_with_external_weights(param, [saved_outputs[v] for v in val])\n",
    "\n",
    "        return saved_outputs\n",
    "\n",
    "    \n",
    "    # x = np.random.random(((1, 28, 28, 1)))\n",
    "\n",
    "    y = flow_input(params, [img])\n",
    "\n",
    "    return branches, layers, requires_output_from, requires_output_to, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = traverse([inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['Input_1', 'Conv2D_1', 'Activation_1', 'Conv2D_2', 'Activation_2', 'Conv2D_3', 'Flatten_1', 'Dense_1', 'Dense_3', 'Flatten_2', 'Dense_2', 'Dense_4'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branches[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74668/544428641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphV2:\n",
    "    allowed_kwargs = {'input', 'inputs', 'output', 'outputs', 'save_branches'}\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.inputs, self.outputs = self._check_args_and_kwargs(*args, **kwargs)\n",
    "        branches, self.multiple_branches = self.get_branches()\n",
    "        self.layers, self.dependencies, self.params = self.create_graph(branches)\n",
    "\n",
    "    def flatten(self, inputs):\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            return list(itertools.chain(inputs))\n",
    "        else:\n",
    "            return [inputs]\n",
    "    \n",
    "    def _check_args_and_kwargs(self, *args, **kwargs):\n",
    "        inputs, outputs = self._check_args(*args)\n",
    "\n",
    "        if not inputs and not outputs:\n",
    "            inputs, outputs = self._check_kwargs(**kwargs)\n",
    "            if not inputs and not outputs:\n",
    "                raise Exception('Cannot create a Model without inputs or outputs')\n",
    "            else:\n",
    "                return inputs, outputs\n",
    "        else:\n",
    "            return inputs, outputs\n",
    "\n",
    "\n",
    "    def _check_args(self, *args):\n",
    "        if len(args) == 0:\n",
    "            return None, None\n",
    "        inputs = self.flatten(args[0])\n",
    "        outputs = self.flatten(args[1])\n",
    "        return inputs, outputs\n",
    "\n",
    "\n",
    "    def _check_kwargs(self, **kwargs):\n",
    "        if len(kwargs) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        for k, v in kwargs.items():\n",
    "            if k not in GraphV2.allowed_kwargs:\n",
    "                raise Exception(f'Unknown argument {k}')\n",
    "            else:\n",
    "                if k == 'input' or k == 'inputs':\n",
    "                    if k == 'input' and isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected a single element found an element in a {type(v)}')\n",
    "                    elif k == 'inputs' and not isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected the element to be found in a list or a tuple found {type(v)}')\n",
    "                    else:\n",
    "                        inputs = self.flatten(v)\n",
    "                    \n",
    "                elif k == 'output' or k == 'outputs':\n",
    "                    if k == 'output' and isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected a single element found an element in a {type(v)}')\n",
    "                    elif k == 'outputs' and not isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected the element to be found in a list or a tuple found {type(v)}')\n",
    "                    else:\n",
    "                        outputs = self.flatten(v)\n",
    "        return inputs, outputs\n",
    "\n",
    "\n",
    "    def get_branches(self):\n",
    "        branches = [OrderedDict([(_input.name, _input)]) for _input in self.inputs]\n",
    "        multiple_branches = len(branches) > 1\n",
    "\n",
    "        main_layers = OrderedDict()\n",
    "        def _traverse(root, branch_index, visited):\n",
    "            nonlocal branches\n",
    "            for r in root._node_container.outbound_nodes:\n",
    "                if r.name not in visited:\n",
    "                    visited.add(r.name)\n",
    "                    if branch_index > 0 and r.name in branches[branch_index-1] and r.name not in main_layers:\n",
    "                        del(branches[branch_index-1][r.name])\n",
    "                        main_layers[r.name] = r\n",
    "                    elif r.name in main_layers:\n",
    "                        continue\n",
    "                    else:\n",
    "                        branches[branch_index][r.name] = r\n",
    "                    \n",
    "                    _traverse(r, branch_index, visited)\n",
    "\n",
    "        for branch_index, _input in enumerate(self.inputs, start=0):\n",
    "            _traverse(root=_input, branch_index=branch_index, visited=set())\n",
    "\n",
    "        return branches, multiple_branches\n",
    "\n",
    "    def create_graph(self, branches):\n",
    "        requires_output_from = OrderedDict()\n",
    "        # requires_output_to = OrderedDict()\n",
    "        layers = OrderedDict([(layer_name, layer) for branch in branches for layer_name, layer in branch.items()])\n",
    "        for layer_name, layer in layers.items():\n",
    "            required_outputs_from = [node.name for node in layer._node_container.inbound_nodes]\n",
    "            requires_output_from[layer_name] = required_outputs_from\n",
    "            # required_outputs_to = [node.name for node in layer._node_container.outbound_nodes]\n",
    "            # requires_output_to[layer_name] = required_outputs_to\n",
    "\n",
    "        params = tuple(layers[layer_name].params for layer_name in requires_output_from.keys())\n",
    "        return layers, requires_output_from, params\n",
    "\n",
    "    \n",
    "    def update_params(self, new_params):\n",
    "        for param, layer_name in zip(new_params, self.dependencies.keys()):\n",
    "            self.layers[layer_name].update_weights(param)\n",
    "    \n",
    "\n",
    "    def call_with_external_weights(self, params, tensors):\n",
    "        saved_outputs = OrderedDict()\n",
    "        consumed_indices = 0\n",
    "        for param, (key, val) in zip(params, self.dependencies.items()):\n",
    "            if len(val) == 0:\n",
    "                saved_outputs[key] = self.layers[key].call_with_external_weights(param, tensors[consumed_indices])\n",
    "                consumed_indices += 1\n",
    "            else:\n",
    "                if len(val) == 1:\n",
    "                    saved_outputs[key] = self.layers[key].call_with_external_weights(param, saved_outputs[val[0]])\n",
    "                else:\n",
    "                    saved_outputs[key] = self.layers[key].call_with_external_weights(param, [saved_outputs[v] for v in val])\n",
    "        if self.multiple_branches:\n",
    "            return [saved_outputs[layer.name] for layer in self.outputs]\n",
    "        else:\n",
    "            return saved_outputs[self.outputs[0].name]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.call_with_external_weights(self.params, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = GraphV2(input=inputs, outputs=[output, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, x, y):\n",
    "    preds = graph.call_with_external_weights(params, [x])\n",
    "    return jnp.mean((preds - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_loss = jax.grad(loss, argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Input_1',\n",
       "               <Input_1 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>),\n",
       "              ('Conv2D_1',\n",
       "               <Conv2D_1 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 64)>),\n",
       "              ('Activation_1',\n",
       "               <Activation_1 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 64)>),\n",
       "              ('Conv2D_2',\n",
       "               <Conv2D_2 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 128)>),\n",
       "              ('Activation_2',\n",
       "               <Activation_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>),\n",
       "              ('Conv2D_3',\n",
       "               <Conv2D_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>),\n",
       "              ('Flatten_1',\n",
       "               <Flatten_1 Layer with input shape (1, 28, 28, 128) and output shape (100352,)>),\n",
       "              ('Dense_1',\n",
       "               <Dense_1 Layer with input shape (100352,) and output shape (None, 512)>),\n",
       "              ('Dense_3',\n",
       "               <Dense_3 Layer with input shape (512,) and output shape (None, 1)>),\n",
       "              ('Flatten_2',\n",
       "               <Flatten_2 Layer with input shape (1, 28, 28, 128) and output shape (100352,)>),\n",
       "              ('Dense_2',\n",
       "               <Dense_2 Layer with input shape (100352,) and output shape (None, 512)>),\n",
       "              ('Dense_4',\n",
       "               <Dense_4 Layer with input shape (512,) and output shape (None, 1)>)])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Input_1 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_1 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 64)>, <Activation_1 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 64)>, <Conv2D_2 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 128)>, <Activation_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_1 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>]\n",
      "[<Input_2 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_4 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 32)>, <Activation_3 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 32)>, <Conv2D_5 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 128)>, <Activation_4 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_6 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>]\n",
      "[<Input_3 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_7 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 32)>, <Activation_5 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 32)>, <Conv2D_8 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 128)>, <Activation_6 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_9 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_10 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Concatenate_1 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 384)>, <Flatten_1 Layer with input shape (1, 28, 28, 384) and output shape (301056,)>, <Dense_1 Layer with input shape (301056,) and output shape (None, 512)>, <Dense_2 Layer with input shape (512,) and output shape (None, 1)>]\n"
     ]
    }
   ],
   "source": [
    "for layer in chain(branches[0]):\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=inputs, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 32/32 [00:06<00:00,  4.84it/s, loss=0.59263736, remaining_epochs=29]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.87it/s, loss=0.45351386, remaining_epochs=28]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.84it/s, loss=0.3545407, remaining_epochs=27] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.48it/s, loss=0.2822816, remaining_epochs=26] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 25.33it/s, loss=0.22832206, remaining_epochs=25]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.59it/s, loss=0.1876095, remaining_epochs=24] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.34it/s, loss=0.15676443, remaining_epochs=23]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.03it/s, loss=0.13296849, remaining_epochs=22]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.60it/s, loss=0.11425949, remaining_epochs=21] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.75it/s, loss=0.09938709, remaining_epochs=20] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 24.59it/s, loss=0.08737737, remaining_epochs=19] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.10it/s, loss=0.0775324, remaining_epochs=18]  \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.67it/s, loss=0.06938313, remaining_epochs=17] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 22.66it/s, loss=0.06255247, remaining_epochs=16] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 22.43it/s, loss=0.05676584, remaining_epochs=15] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 22.15it/s, loss=0.051811337, remaining_epochs=14]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.31it/s, loss=0.047537994, remaining_epochs=13]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 22.64it/s, loss=0.043828964, remaining_epochs=12]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 23.76it/s, loss=0.040581793, remaining_epochs=11]\n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 22.52it/s, loss=0.03772165, remaining_epochs=10] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 21.99it/s, loss=0.03519062, remaining_epochs=9] \n",
      "100%|████████████████████████████████████████| 32/32 [00:01<00:00, 21.64it/s, loss=0.032936826, remaining_epochs=8]\n",
      " 56%|██████████████████████▌                 | 18/32 [00:00<00:00, 22.71it/s, loss=0.03184072, remaining_epochs=7] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15555/1202452928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kerax/kerax/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, batch_size, steps, shuffle, validation_data)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar:40}{r_bar}{bar:-20b}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kerax/kerax/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mcurrent_batch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mcurrent_batch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mcurrent_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   5702\u001b[0m   \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5703\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5704\u001b[0;31m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0m\u001b[1;32m   5705\u001b[0m                  unique_indices, mode, fill_value)\n\u001b[1;32m   5706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   5711\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   5712\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5713\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5714\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5965\u001b[0m           \u001b[0mreversed_y_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollapsed_y_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5966\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5967\u001b[0;31m           \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5968\u001b[0m           \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5969\u001b[0m           \u001b[0mslice_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mconvert_element_type\u001b[0;34m(operand, new_dtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__jax_array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0moperand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__jax_array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m def _convert_element_type(operand: Array, new_dtype: Optional[DType] = None,\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m     return convert_element_type_p.bind(operand, new_dtype=new_dtype,\n\u001b[0m\u001b[1;32m    495\u001b[0m                                        weak_type=new_weak_type)\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    277\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args),\n\u001b[0m\u001b[1;32m     79\u001b[0m                                         **params)\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6721b10ec9b0eeb463be84ab6ef1ed3e9e9b165baec57fa1847c389edb595caf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('jax': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
