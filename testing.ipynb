{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2022-04-05 17:17:02.335534: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
=======
      "2022-04-04 05:30:07.413000: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
>>>>>>> b3e4487c948cd621f370a16a7ea2ca4248d249d0
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jax import lax\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "import kerax\n",
    "from kerax import utils\n",
    "from kerax.layers import (Activation, Add, Concatenate, Conv2D, Dense, Flatten,\n",
    "                          Input, Layer, MultiHeadAttention)\n",
    "from kerax.models import Model\n"
=======
    "from kerax.layers import Conv2D, Dense, Flatten, Input, Activation, Add, Concatenate\n",
    "from kerax.models import Model\n",
    "from jax.random import PRNGKey\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import jax"
>>>>>>> b3e4487c948cd621f370a16a7ea2ca4248d249d0
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "df = pd.read_csv('train.csv')"
=======
    "img = random.normal(key=PRNGKey(3), shape=(2, 28, 28, 1))\n",
    "\n",
    "# train_x = random.normal(key=PRNGKey(3), shape=(128, 28, 28, 1))\n",
    "# train_y = random.randint(key=PRNGKey(34), shape=(128, 1), minval=0, maxval=1)"
>>>>>>> b3e4487c948cd621f370a16a7ea2ca4248d249d0
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "labels = df['label'].values"
=======
    "inputs = Input(shape=(28, 28, 1))\n",
    "conv1 = Conv2D(64, 3, key=PRNGKey(100), padding='same')(inputs)\n",
    "act1 = Activation('leaky_relu')(conv1)\n",
    "conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(act1)\n",
    "act2 = Activation('leaky_relu')(conv3)\n",
    "conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(act2)\n",
    "# add1 = Add()([conv4, act2])\n",
    "\n",
    "# inputs2 = Input(shape=(28, 28, 1))\n",
    "# inputs2_conv1 = Conv2D(32, 3, key=PRNGKey(100), padding='same')(inputs2)\n",
    "# inputs2_act1 = Activation('relu')(inputs2_conv1)\n",
    "# inputs2_conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs2_act1)\n",
    "# inputs2_act2 = Activation('gelu')(inputs2_conv3)\n",
    "# inputs2_conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(inputs2_act2)\n",
    "# add2 = Add()([inputs2_conv4, inputs2_act2])\n",
    "\n",
    "\n",
    "# inputs3 = Input(shape=(28, 28, 1))\n",
    "# inputs3_conv1 = Conv2D(32, 3, key=PRNGKey(100), padding='same')(inputs3)\n",
    "# inputs3_act1 = Activation('relu')(inputs3_conv1)\n",
    "# inputs3_conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs3_act1)\n",
    "# inputs3_act2 = Activation('gelu')(inputs3_conv3)\n",
    "# inputs3_conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(inputs3_act2)\n",
    "# inputs3_conv5 = Conv2D(128, 3, padding='same', key=PRNGKey(105))(inputs3_conv4)\n",
    "# add3 = Add()([inputs3_conv5, inputs3_act2])\n",
    "\n",
    "# cat = Concatenate()([add1, add2, add3])\n",
    "\n",
    "flatten1 = Flatten()(conv4)\n",
    "flatten2 = Flatten()(act2)\n",
    "dense1 = Dense(512, activation='leaky_relu')(flatten1)\n",
    "dense2 = Dense(512)(flatten2)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "output2 = Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(inputs):\n",
    "    branches = [OrderedDict([(_input.name, _input)]) for _input in inputs]\n",
    "    main_layers = OrderedDict()\n",
    "    def _traverse(root, branch_index, visited):\n",
    "        nonlocal branches\n",
    "        for r in root._node_container.outbound_nodes:\n",
    "            if r.name not in visited:\n",
    "                visited.add(r.name)\n",
    "                if branch_index > 0 and r.name in branches[branch_index-1] and r.name not in main_layers:\n",
    "                    del(branches[branch_index-1][r.name])\n",
    "                    main_layers[r.name] = r\n",
    "                elif r.name in main_layers:\n",
    "                    continue\n",
    "                else:\n",
    "                    branches[branch_index][r.name] = r\n",
    "                _traverse(r, branch_index, visited)\n",
    "\n",
    "    for branch_index, _input in enumerate(inputs, start=0):\n",
    "        _traverse(root=_input, branch_index=branch_index, visited=set())\n",
    "\n",
    "    def create_graph():\n",
    "        nonlocal branches\n",
    "        requires_output_from = OrderedDict()\n",
    "        requires_output_to = OrderedDict()\n",
    "        layers = OrderedDict([(layer_name, layer) for branch in branches for layer_name, layer in branch.items()])\n",
    "\n",
    "        layers.update(main_layers)\n",
    "        for layer_name, layer in layers.items():\n",
    "            required_outputs_from = [node.name for node in layer._node_container.inbound_nodes]\n",
    "            required_outputs_to = [node.name for node in layer._node_container.outbound_nodes]\n",
    "            requires_output_from[layer_name] = required_outputs_from\n",
    "            requires_output_to[layer_name] = required_outputs_to\n",
    "\n",
    "\n",
    "        return layers, requires_output_from, requires_output_to\n",
    "\n",
    "    layers, requires_output_from, requires_output_to = create_graph()\n",
    "\n",
    "    params = []\n",
    "    for l_name, l_param in requires_output_from.items():\n",
    "        params.append(layers[l_name].params)\n",
    "\n",
    "    params = tuple(params)\n",
    "\n",
    "    def flow_input(params, tensors):\n",
    "        saved_outputs = OrderedDict()\n",
    "        nonlocal layers, requires_output_from, requires_output_to\n",
    "        consumed_indices = 0\n",
    "        for param, (key, val) in zip(params, requires_output_from.items()):\n",
    "            if len(val) == 0:\n",
    "                saved_outputs[key] = layers[key].call_with_external_weights(param, tensors[consumed_indices])\n",
    "                consumed_indices += 1\n",
    "            else:\n",
    "                if len(val) == 1:\n",
    "                    saved_outputs[key] = layers[key].call_with_external_weights(param, saved_outputs[val[0]])\n",
    "                else:\n",
    "                    saved_outputs[key] = layers[key].call_with_external_weights(param, [saved_outputs[v] for v in val])\n",
    "\n",
    "        return saved_outputs\n",
    "\n",
    "    \n",
    "    # x = np.random.random(((1, 28, 28, 1)))\n",
    "\n",
    "    y = flow_input(params, [img])\n",
    "\n",
    "    return branches, layers, requires_output_from, requires_output_to, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = traverse([inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['Input_1', 'Conv2D_1', 'Activation_1', 'Conv2D_2', 'Activation_2', 'Conv2D_3', 'Flatten_1', 'Dense_1', 'Dense_3', 'Flatten_2', 'Dense_2', 'Dense_4'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branches[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74668/544428641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphV2:\n",
    "    allowed_kwargs = {'input', 'inputs', 'output', 'outputs', 'save_branches'}\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.inputs, self.outputs = self._check_args_and_kwargs(*args, **kwargs)\n",
    "        branches, self.multiple_branches = self.get_branches()\n",
    "        self.layers, self.dependencies, self.params = self.create_graph(branches)\n",
    "\n",
    "    def flatten(self, inputs):\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            return list(itertools.chain(inputs))\n",
    "        else:\n",
    "            return [inputs]\n",
    "    \n",
    "    def _check_args_and_kwargs(self, *args, **kwargs):\n",
    "        inputs, outputs = self._check_args(*args)\n",
    "\n",
    "        if not inputs and not outputs:\n",
    "            inputs, outputs = self._check_kwargs(**kwargs)\n",
    "            if not inputs and not outputs:\n",
    "                raise Exception('Cannot create a Model without inputs or outputs')\n",
    "            else:\n",
    "                return inputs, outputs\n",
    "        else:\n",
    "            return inputs, outputs\n",
    "\n",
    "\n",
    "    def _check_args(self, *args):\n",
    "        if len(args) == 0:\n",
    "            return None, None\n",
    "        inputs = self.flatten(args[0])\n",
    "        outputs = self.flatten(args[1])\n",
    "        return inputs, outputs\n",
    "\n",
    "\n",
    "    def _check_kwargs(self, **kwargs):\n",
    "        if len(kwargs) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        for k, v in kwargs.items():\n",
    "            if k not in GraphV2.allowed_kwargs:\n",
    "                raise Exception(f'Unknown argument {k}')\n",
    "            else:\n",
    "                if k == 'input' or k == 'inputs':\n",
    "                    if k == 'input' and isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected a single element found an element in a {type(v)}')\n",
    "                    elif k == 'inputs' and not isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected the element to be found in a list or a tuple found {type(v)}')\n",
    "                    else:\n",
    "                        inputs = self.flatten(v)\n",
    "                    \n",
    "                elif k == 'output' or k == 'outputs':\n",
    "                    if k == 'output' and isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected a single element found an element in a {type(v)}')\n",
    "                    elif k == 'outputs' and not isinstance(v, (list, tuple)):\n",
    "                        raise Exception(f'Expected the element to be found in a list or a tuple found {type(v)}')\n",
    "                    else:\n",
    "                        outputs = self.flatten(v)\n",
    "        return inputs, outputs\n",
    "\n",
    "\n",
    "    def get_branches(self):\n",
    "        branches = [OrderedDict([(_input.name, _input)]) for _input in self.inputs]\n",
    "        multiple_branches = len(branches) > 1\n",
    "\n",
    "        main_layers = OrderedDict()\n",
    "        def _traverse(root, branch_index, visited):\n",
    "            nonlocal branches\n",
    "            for r in root._node_container.outbound_nodes:\n",
    "                if r.name not in visited:\n",
    "                    visited.add(r.name)\n",
    "                    if branch_index > 0 and r.name in branches[branch_index-1] and r.name not in main_layers:\n",
    "                        del(branches[branch_index-1][r.name])\n",
    "                        main_layers[r.name] = r\n",
    "                    elif r.name in main_layers:\n",
    "                        continue\n",
    "                    else:\n",
    "                        branches[branch_index][r.name] = r\n",
    "                    \n",
    "                    _traverse(r, branch_index, visited)\n",
    "\n",
    "        for branch_index, _input in enumerate(self.inputs, start=0):\n",
    "            _traverse(root=_input, branch_index=branch_index, visited=set())\n",
    "\n",
    "        return branches, multiple_branches\n",
    "\n",
    "    def create_graph(self, branches):\n",
    "        requires_output_from = OrderedDict()\n",
    "        # requires_output_to = OrderedDict()\n",
    "        layers = OrderedDict([(layer_name, layer) for branch in branches for layer_name, layer in branch.items()])\n",
    "        for layer_name, layer in layers.items():\n",
    "            required_outputs_from = [node.name for node in layer._node_container.inbound_nodes]\n",
    "            requires_output_from[layer_name] = required_outputs_from\n",
    "            # required_outputs_to = [node.name for node in layer._node_container.outbound_nodes]\n",
    "            # requires_output_to[layer_name] = required_outputs_to\n",
    "\n",
    "        params = tuple(layers[layer_name].params for layer_name in requires_output_from.keys())\n",
    "        return layers, requires_output_from, params\n",
    "\n",
    "    \n",
    "    def update_params(self, new_params):\n",
    "        for param, layer_name in zip(new_params, self.dependencies.keys()):\n",
    "            self.layers[layer_name].update_weights(param)\n",
    "    \n",
    "\n",
    "    def call_with_external_weights(self, params, tensors):\n",
    "        saved_outputs = OrderedDict()\n",
    "        consumed_indices = 0\n",
    "        for param, (key, val) in zip(params, self.dependencies.items()):\n",
    "            if len(val) == 0:\n",
    "                saved_outputs[key] = self.layers[key].call_with_external_weights(param, tensors[consumed_indices])\n",
    "                consumed_indices += 1\n",
    "            else:\n",
    "                if len(val) == 1:\n",
    "                    saved_outputs[key] = self.layers[key].call_with_external_weights(param, saved_outputs[val[0]])\n",
    "                else:\n",
    "                    saved_outputs[key] = self.layers[key].call_with_external_weights(param, [saved_outputs[v] for v in val])\n",
    "        if self.multiple_branches:\n",
    "            return [saved_outputs[layer.name] for layer in self.outputs]\n",
    "        else:\n",
    "            return saved_outputs[self.outputs[0].name]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.call_with_external_weights(self.params, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = GraphV2(input=inputs, outputs=[output, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, x, y):\n",
    "    preds = graph.call_with_external_weights(params, [x])\n",
    "    return jnp.mean((preds - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_loss = jax.grad(loss, argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Input_1',\n",
       "               <Input_1 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>),\n",
       "              ('Conv2D_1',\n",
       "               <Conv2D_1 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 64)>),\n",
       "              ('Activation_1',\n",
       "               <Activation_1 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 64)>),\n",
       "              ('Conv2D_2',\n",
       "               <Conv2D_2 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 128)>),\n",
       "              ('Activation_2',\n",
       "               <Activation_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>),\n",
       "              ('Conv2D_3',\n",
       "               <Conv2D_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>),\n",
       "              ('Flatten_1',\n",
       "               <Flatten_1 Layer with input shape (1, 28, 28, 128) and output shape (100352,)>),\n",
       "              ('Dense_1',\n",
       "               <Dense_1 Layer with input shape (100352,) and output shape (None, 512)>),\n",
       "              ('Dense_3',\n",
       "               <Dense_3 Layer with input shape (512,) and output shape (None, 1)>),\n",
       "              ('Flatten_2',\n",
       "               <Flatten_2 Layer with input shape (1, 28, 28, 128) and output shape (100352,)>),\n",
       "              ('Dense_2',\n",
       "               <Dense_2 Layer with input shape (100352,) and output shape (None, 512)>),\n",
       "              ('Dense_4',\n",
       "               <Dense_4 Layer with input shape (512,) and output shape (None, 1)>)])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Input_1 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_1 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 64)>, <Activation_1 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 64)>, <Conv2D_2 Layer with input shape (1, 28, 28, 64) and output shape (1, 28, 28, 128)>, <Activation_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_1 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>]\n",
      "[<Input_2 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_4 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 32)>, <Activation_3 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 32)>, <Conv2D_5 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 128)>, <Activation_4 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_6 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_2 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>]\n",
      "[<Input_3 Layer with input shape (28, 28, 1) and output shape (28, 28, 1)>, <Conv2D_7 Layer with input shape (1, 28, 28, 1) and output shape (1, 28, 28, 32)>, <Activation_5 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 32)>, <Conv2D_8 Layer with input shape (1, 28, 28, 32) and output shape (1, 28, 28, 128)>, <Activation_6 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_9 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Conv2D_10 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Add_3 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 128)>, <Concatenate_1 Layer with input shape (1, 28, 28, 128) and output shape (1, 28, 28, 384)>, <Flatten_1 Layer with input shape (1, 28, 28, 384) and output shape (301056,)>, <Dense_1 Layer with input shape (301056,) and output shape (None, 512)>, <Dense_2 Layer with input shape (512,) and output shape (None, 1)>]\n"
     ]
    }
   ],
   "source": [
    "for layer in chain(branches[0]):\n",
    "    print(layer)"
>>>>>>> b3e4487c948cd621f370a16a7ea2ca4248d249d0
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = df.values.reshape((df.shape[0], 28, 28, 1)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazem/miniconda3/envs/jax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py:5154: UserWarning: Explicitly requested dtype int requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax_internal._check_user_dtype_supported(dtype, \"astype\")\n"
     ]
    }
   ],
   "source": [
    "cat_train_y = utils.to_categorical(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerax.backend.enable_jit_execution(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "conv1 = Conv2D(64, 3, padding='same', key=PRNGKey(100))(inputs)\n",
    "act1 = Activation('relu')(conv1)\n",
    "conv3 = Conv2D(128, 3, padding='same', key=PRNGKey(104))(act1)\n",
    "act2 = Activation('relu')(conv3)\n",
    "conv4 = Conv2D(128, 3, padding='same', key=PRNGKey(105), activation='relu')(act2)\n",
    "add = Add()([act2, conv4])\n",
    "flatten = Flatten()(add)\n",
    "dense1 = Dense(512, activation='relu')(flatten)\n",
    "output = Dense(10, activation='softmax')(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|===============                         | 131/328 [02:21<03:32,  1.08s/it, Loss=14.894131]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20750/975708976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kerax/kerax/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, batch_size, steps, shuffle, validation_data)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kerax/kerax/models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;34m'Returns loss value and takes training batch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# loss = self.loss_fn(self.graph.params, x, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kerax/kerax/optimizers/optimizers.py\u001b[0m in \u001b[0;36mget_loss_and_gradients\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m'Increment step index'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loss_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m'Returns the loss value and the gradients'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(imgs, cat_train_y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6721b10ec9b0eeb463be84ab6ef1ed3e9e9b165baec57fa1847c389edb595caf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('jax': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
